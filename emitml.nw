% -*- mode: Noweb; noweb-code-mode: icon-mode -*-
\section{Emitting ML code}
<<*>>=
procedure ML(what)
  return case(what) of {
    "emit"           : MLEmitnt
    "preamble"       : MLEmitPreamble
    "postamble"      : MLEmitPostamble
    "stringdef"      : MLStringdef
    "infersemantics" : MLSemantics
    "precedence"     : MLPrec
    "lr"             : MLLR
    "append"	     : MLAppend
    "nil"	     : "[]"
    "some"	     : MLSome
    "none"	     : "NONE"
    "resynch"        : MLResynch
    default : error("ML doesn't support ", what)
  }
end
<<*>>=
procedure MLResynch(pos)
  return write("(*#line ", pos.lineno, " ", image(pos.filename), "*)")
end
<<*>>=
procedure MLEmitPreamble(g)
  local do_rgn, token
  do_rgn := g.attributes["region"]
  token := ((\g.attributes["token"])[1] | "Token")
  <<emit [[ii.tab.sml]] file>>
  emit_templates(
     <<template list>>,
     "parser",    ((\g.attributes["parser"])[1] | "Parser"), 
     "Token",     token,
     "lexresult", if /do_rgn then "'a" else "'a * (int*int)",
     "tokenlex",  if /do_rgn then "token, lex" else "token, trgn, lex",
     <<template pairs>>)
  default_emit_preamble(g, ML)
  write()
  <<emit ``untoken'' functions>>
  return
end
<<template list>>=                      
[
"structure %parser = struct",
"  datatype 'a stream = STREAM of unit -> %lexresult * 'a stream",
"  fun invoke (STREAM lex) = lex()",
"  ",
"  type token = %Token.token",
"  ",
"  exception SyntaxError of {parsing:string, msg:string list, found:token%{region:region}}",
"  exception Expected of {expected:string, found:token, parsing:string option} ",
"	   (* token expected, nonterminal being parsed *)",
"  ",
if \g.attributes["arg-pat"] then {
  s := "fun makeParser (" 
  every s ||:= !g.attributes["arg-pat"] || " "
  s ||:= ") = let"
} else
  "local",
<<closing of parser>>=
write("in")
if /g.attributes["arg-pat"] then 
  writes("  val parser =")
write("  make_parser(P_", g.start, ", unEOF)")
write("end (*local*)")
@ 
<<template list>>=
"  open %Token",
"  ",
if /do_rgn then &null 
else [
  "  val nullRegion = (0, 0)",
  "  fun span ((0,0), r) = r",
  "    | span (r, (0,0)) = r", 
  "    | span ((l1, h1), (l2, h2)) = if l1 < h2 then (l1, h2) else (l2, h1)",
  "  fun startRegion (first, last) = (first, first)",
  ""],
"  exception TokenMismatch of string",
"  fun expect (f, %tokenlex, nt) =",
"    (f token%trgn, invoke lex) handle TokenMismatch t => ",
"         raise Expected {expected=t, found=token, parsing=nt}",
"  ",
"  fun synerror (t%trgn, nt, s) = raise SyntaxError {parsing=nt, found=t, msg=s%{region=trgn}}",
"  ",
"  ",
"  (* closure and optional for parsing *)",
"  fun closure((%tokenlex), predicate, parse) =",
"    let fun cl(%tokenlex, l%{rgn'}) =",
"	   if predicate token then",
"	     let val (x%rgn, (%tokenlex)) = parse(%tokenlex)",
"	     in  cl(%tokenlex, x::l%{region_span})",
"	     end",
"	   else",
"	     (rev l%{rgn'}, (%tokenlex))",
"    in  cl(%tokenlex, []%yyrgn)",
"    end",
<<template pairs>>=
"rgn",           if /do_rgn then "" else ", rgn",
"rgn'",          if /do_rgn then "" else ", rgn'",
"trgn",          if /do_rgn then "" else ", trgn",
"region=trgn", 	 if /do_rgn then "" else ", region=trgn",
"region:region", if /do_rgn then "" else ", region:int*int",
"region_span", 	 if /do_rgn then "" else ", span(rgn, rgn')",
"nullRegion",    if /do_rgn then "" else ", nullRegion",
"yyrgn",       	 if /do_rgn then "" else ", startRegion trgn",
<<template list>>=
"  ",
"  fun optional((%tokenlex), predicate, parse) = ",
"     if predicate token then ",
"	let val (x%rgn, (%tokenlex)) = parse(%tokenlex)",
"	in  (SOME x%rgn, (%tokenlex))",
"	end",
"     else ",
"	(NONE%yyrgn, (%tokenlex))",
# N.B. we really should do better here --- instead of null region, 
# we could use the empty region immediately preceding the non-satisfying token.
"  ",
"  fun make_parser (f, unEOF) stream =",
"    let val (result%rgn, (%tokenlex)) = f (invoke stream)",
"    in  (unEOF token; result) handle TokenMismatch _ => ",
"          raise Expected {expected=\"end of file\", found=token, parsing=NONE} ",
"    end",
"  ",
""]
@ 
<<*>>=
procedure emit_templates(templates, pairs[])
  t := table()
  while k := get(pairs) do t[k] := get(pairs)
##  write(&errout, "Templates: ")
##  every k := key(t) do write(&errout, "  ", k, " --> ", t[k])
  return emit_templates_tab(templates, t)
end

procedure emit_templates_tab(templates, t)
  every s := !templates do 
    case type(s) of {
      "&null" : &null
      "string" : 
	 s ? {
           while writes(tab(upto('%'))) do {
             ="%"
             if ="%" then 
               writes("%")
             else if (="{", k := tab(upto('}')), ="}") | (k :=tab(many(&letters))) then
               writes(t[k] | stop(k, " unbound in template"))
             else 
               stop("Ill-formed % construct in template: (",
                    image(move(3) || "..." | tab(0)), ")")
           }
           write(tab(0))
         }
      "list" : emit_templates_tab(s, t)
    }
  return
end
@ 
<<*>>=
procedure MLEmitPostamble(g)
  default_emit_postamble(g, ML)
  <<closing of parser>>
  write("end (* Parser *)")
  return
end
<<*>>=
global ITAB, thisnt, track_regions, tokenlex
global iitabfilename
procedure MLEmitnt(g, nt)
  local outfile
  static fun
  initial {
    ITAB := 4
    fun := "fun"
  }
  track_regions := g.attributes["region"]
  tokenlex := if /track_regions then "token, lex" else "token, trgn, lex"
  write(fun, " P_", thisnt := nt, "(", tokenlex, ") =")
  fun := "and"
  write(if type(g.nonterms[nt]) ~== "Alt" then 
              " # " || prodimage(nt[1], g.nonterms[nt]) else "")
  MLEmitnode(g, nt, g.nonterms[nt], ITAB)
end
<<emit [[ii.tab.sml]] file>>=
outfile := open(\iitabfilename | "ii.tab.sml", "w") |
           stop("can't open " ||  (\iitabfilename | "ii.tab.sml"))
write(outfile, "signature ", mixcaps_to_allcaps(token), " = sig")
emit_ml_token_datatype(outfile, g)
write(outfile, "val reserved   : string -> token option")
write(outfile, "val unReserved : token  -> string option")
write(outfile, "end")

write(outfile, "structure ", token, " : ", mixcaps_to_allcaps(token), " = struct")
emit_ml_tokendef(outfile, g)
emit_ml_reserved(outfile, g)
write(outfile, "end")
close(outfile)
@ 
<<emit ``untoken'' functions>>=
write("(*#line ", 0, " ", image("generated code"), "*)")
l := sort(g.leaves)
every t := !l & member(g.terms, t) do {
  if /g.termtypes[t] then { pat := g.terms[t]; val := t }    
  else                    { pat := "(" || g.terms[t] || " x)"; val := "x" }
  write("  fun un", g.terms[t], " ", pat, " = ", val)
  write("    | un", g.terms[t], " _ = raise TokenMismatch ", image(t))
}    
write("  fun unEOF EOF = \"end of file\"")
write("    | unEOF _ = raise TokenMismatch \"end of file\"")
write()
@ 
We could automatically keep track of source-code regions, but only on
request.
<<*>>=
procedure ML_pattern_elements(k)
  s := "ii" || k
  if \track_regions then
    s ||:= ", rr" || k
  return s
end
    
@
<<*>>=
procedure MLEmitnode(g, nt, node, indent)
  local initindent, ofword
  static fakeline
  initial {fakeline := create(seq(1000, 1000))
          }
  initindent := indent
  case type(node) of {
    "Alt" : {
        iwrite(indent, "let (*Alt*) ")
        every i := 1 to *node.list & n := node.list[i] do {
          iwrites(indent+ITAB, "fun alt", i, " () = ")
          write("(* ", 
                if g.nonterms[l := key(g.nonterms)] === node then prodimage(l, n) 
                else nodeimage(n), " *)")
          MLEmitnode(g, nt, n, indent+2*ITAB)
        }
        iwrite(indent, "in")
        iwrite(indent+ITAB, "case token")
        ofword := "of"
        every i := 1 to *node.list & n := node.list[i] & 
              t := ml_token_pat(g, !sort(predict(n, node)))
        do {
          iwrite(indent+2*ITAB, ofword, " ", t, " => alt", i, "()")
          ofword := " |"
        }          
        iwrite(indent+2*ITAB, ofword, " t => ", mlsyntax(node, "t"))
        iwrite(indent, "end")
      }
    "Cat" : {
        iwrite(indent, "let (*Cat*) ")
        every i := 1 to *node.list do {
          iwrite(indent + ITAB,
                 "val (", ML_pattern_elements(i), ", (", tokenlex, ")) =")
          MLEmitnode(g, nt, node.list[i], indent + 2*ITAB)
        }
        if \track_regions then 
          iwrite(indent+ITAB, "val rr0 = ",
                 case *node.list of {
		   0 : "startRegion trgn"
		   1 : "rr1"
		   default : "span(rr1, rr" || *node.list || ")"
		 })
        iwrite(indent+ITAB, "val result = (")
        write("(*#line ", adjustline(\node.position), "*)")
        every iwrite(indent+ITAB, !\node.semantics)
        write("(*#line ", \node.position & @fakeline, image("generated code"), "*)")
        iwrite(indent+ITAB, ")")
        iwrite(indent,   "in  (result, ", if \track_regions then "rr0, " else "",
	                      "(", tokenlex, "))")
        if \g.attributes["trace"] then
          iwrite(indent, "    before print ", image("reduced " || nt || "\n"))
        iwrite(indent, "end")
        }
    "Opt" | "Clo" : {
      f := if type(node) == "Opt" then "optional" else "closure"
      iwrite(initindent, "(", f, "((", tokenlex, "), (")
      fn := "fn (*" || type(node) || "*) "
      every t := ml_token_pat(g, !sort(first[node]--epsilonset)) do {
        iwrite(indent+ITAB, fn, " ", t, " => true")
        fn := " |"
      }
      iwrite(indent+ITAB, fn, " _ => false),")
      iwrite(indent, "(fn (", tokenlex, ") => ")
      MLEmitnode(g, nt, node.node, indent+2*ITAB)
      iwrite(indent+ITAB, ")))")
    }
    "string" : 
       iwrite(initindent, "expect(un", \g.terms[node], ", ", tokenlex, ", ",
                                  "SOME ", image(thisnt), ")") | 
         iwrite(initindent, "P_", node, "(", tokenlex, ")")
    default : error("this can't happen -- error node type")
  }
  return
end
@
Print different syntax error messages according to the number of alternatives.
<<*>>=
link commafy
procedure mlsyntax(alt, token)
  local rgn
  s := set()
  every s ++:= predict(!alt.list, alt)
  rgn := if /track_regions then "" else ", trgn"
  return case *s of {
    0 : error("Empty predict set in production for `", thisnt, "'! Can this happen?")
    1 | 2 | 3 :
       map("synerror(" || token || rgn || ", " || "#" || thisnt || "#, [#expected " || 
           map(commafy(sort(s), "or"), "\"", "'") || "#])", "#", "\"")
    default : map("synerror(" || token || rgn || ", #" || thisnt || "#, [])", "#", "\"")
  }
end
@
[[iwrite]] and [[iwrites]] are used for indentation.
@
Define nonterminals
<<*>>=
global MLReserved

procedure MLStringdef(g)
  MLReserved := set()
  every t := !g.leaves & not member(g.nonterms, t) do
    if any('"\'', t[1] == t[-1]) then {
      /g.terms[t] := mltokname(t[2:-1])
      insert(MLReserved, t)
    }
  every t := key(g.terms) do /g.terms[t] := t
  return g
end
<<*>>=
procedure emit_ml_reserved(outfile, g)
  local prefix, nprefix
  prefix  := "fun reserved "
  nprefix := "  | reserved "
  every t := !sort(MLReserved) do {
    write(outfile, prefix, t, " = SOME ", g.terms[t])
    prefix := nprefix
  }    
  write(outfile, nprefix, " _ = NONE")
  write(outfile)

  prefix  := "fun unReserved "
  nprefix := "  | unReserved "
  every t := !sort(MLReserved) do {
    write(outfile, prefix, g.terms[t], " = SOME ", t)
    prefix := nprefix
  }    
  write(outfile, nprefix, " _ = NONE")
  write(outfile)

  return g
end
<<*>>=
procedure MLSemantics(g)
  every MLdosem(g, !g.nonterms)
  return
end

procedure MLdosem(g, node)
  case type(node) of {
    "Opt" | "Clo" : MLdosem(g, node.node)
    "Alt" : every MLdosem(g, !node.list)
    "Cat" : {
       every MLdosem(g, !node.list)
       node.semantics := [case type(node.semantics) of {
         "null" : {
            "ii" || copy_number(g, node) | {
              s := "["
              every s ||:= "ii" || (1 to *node.list) || ", "
              s[1:-2] || "]" | "NONE"
            }
          }
         "string" : MLSemanticTag(g, node, node.semantics)
         "allargs" : node.semantics.ident || "(" ||
                      arg_list("ii", {l := []; every put(l, 1 to *node.list); l}) || ")"
       }]
     }
    "string" : &fail
    default  : error("impossible node type")
  }
end
<<*>>=
procedure MLSemanticTag(g, catnode, ident)
  return ident || "(" || arg_list("ii", arg_numbers(g, catnode)) || ")"
end
@
<<*>>=
procedure MLPrec(g)
  local fun
  fun := "fun"
  every p := !sort(g.prec, 2) & term := p[1] do {
    write(fun, " prec ", term, " = ", p[2]) 
    fun  := "  |"
  }
  write(fun, " prec _ = raise Prec")
  fun := "fun"
  every p := !sort(g.prec, 2) & term := p[1] do {
    write(fun, " assoc ", term, " = ", image(g.assoc[p[1]]))
    fun  := "  |"
  }
  write(fun, " assoc _ = raise Prec")
  return
end
<<*>>=
procedure MLAppend(list, x)
  return "(" || list || "@ [" || x || "])"
end

procedure MLSome(l, n)
  case *\l of {
      0 : fail
      1 : l[1] := "SOME (" || l[1] || ")"
      default : { push(l, "SOME ("); put(l, ")")
                  n.position := n.position ?
                    if l := tab(upto(' ')) then (l-1) || tab(0) 
                }
  }
  return \l
end
<<*>>=
procedure emit_ml_tokendef(outfile, g)
  local prefix, arg, val
  emit_ml_token_datatype(outfile, g)
###  write(outfile, "exception TokenMismatch of string")
  write(outfile)
end
<<*>>=
procedure emit_ml_token_datatype(outfile, g)
  local prefix
  l := sort(g.leaves)
  write (outfile, "datatype token = EOF")
  prefix :=       "               | "
  every t := !l & member(g.terms, t) do
    write(outfile, prefix, g.terms[t], 
          if /g.termtypes[t] then "" else " of " || g.termtypes[t])
  write(outfile)
  return
end
<<*>>=
procedure ml_token_pat(g, t)
  return if /g.termtypes[t] then g.terms[t] else "(" || g.terms[t] || " _)"
end
@ 
<<*>>=
procedure mixcaps_to_allcaps(s)
  s ? {
    tab(many(' \t'))
    t := map(move(1), &lcase, &ucase) | ""
    while t ||:= map(tab(upto(&ucase)), &lcase, &ucase) || "_" do
      t ||:= move(1)
    return t || map(tab(0), &lcase, &ucase)
  }
end
<<mlfuns.t>>=
(* set functions *)
type 'a set = 'a list
val emptyset : 'a set = []
fun member(x, [])   = false
  | member(x, h::t) = x = h orelse member(x, t)
fun insert(x, l) = if member(x, l) then l else x::l
fun delete(x, [])   = []
  | delete(x, h::t) = if x = h then t else h :: delete(x, t)

(* lexing *)

datatype 'a stream = STREAM of unit -> 'a * 'a stream
fun invoke (STREAM lex) = lex()

exception TokenMismatch of string
exception Expected of string * string option 
	(* token expected, nonterminal being parsed *)

fun expect (f, token, lex, nt) =
  (f token, invoke lex) handle TokenMismatch t => raise Expected(t, nt)

exception SyntaxError of string
fun synerror s = raise SyntaxError s


(* closure and optional for parsing *)
fun closure((token, lex), predicate, parse) =
  let fun cl(token, lex, l) =
        if predicate token then
          let val (x, (token, lex)) = parse(token, lex)
          in  cl(token, lex, x::l)
          end
        else
          (rev l, (token, lex))
  in  cl(token, lex, [])
  end

fun optional((token, lex), predicate, parse) = 
   if predicate token then 
     let val (x, (token, lex)) = parse(token, lex)
     in  (SOME x, (token, lex))
     end
   else 
     (NONE, (token, lex))

exception LeftoverTokens of token stream
fun make_parser (f, unEOF) stream =
  let val (result, (token, lex)) = f (invoke stream)
  in  (unEOF token; result) handle TokenMismatch _ => raise LeftoverTokens stream
  end
